{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fc788ee9",
   "metadata": {},
   "source": [
    "# Pretraining On Unlabeled Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "61eb852c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import torch\n",
    "# Add the parent directory to sys.path so chapter_4 can be imported\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '..')))\n",
    "from chapter_4.chapter04 import GPTModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "688e783e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPT-2 small\n",
    "GPT_CONFIG_124M = {\n",
    "    \"vocab_size\": 50257,    # Vocabulary size\n",
    "    \"context_length\": 256, # Context length\n",
    "    \"emb_dim\": 768,         # Embedding dimension\n",
    "    \"n_heads\": 12,          # Number of attention heads\n",
    "    \"n_layers\": 12,         # Number of transformer blocks\n",
    "    \"drop_rate\": 0.1,       # Dropout rate\n",
    "    \"qkv_bias\": False       # Query-Key-Value bias\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "376f1ee7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (tok_emb): Embedding(50257, 768)\n",
       "  (pos_emb): Embedding(256, 768)\n",
       "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c696ba29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text:\n",
      " Every effort moves you rentingetic wasnÙ… refres RexMeCHicular stren\n"
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "from chapter_4.chapter04 import generate_text_sample\n",
    "\n",
    "def text_to_token_ids(text, tokenizer):\n",
    "    encoded = tokenizer.encode(text, allowed_special={'<|endoftext|>'})\n",
    "    encoded_tensor = torch.tensor(encoded).unsqueeze(0) # unsqueeze adds batch dimensions\n",
    "    return encoded_tensor\n",
    "\n",
    "def token_ids_to_text(token_ids, tokenizer):\n",
    "    flat = token_ids.squeeze(0)\n",
    "    return tokenizer.decode(flat.tolist())\n",
    "\n",
    "start_context = \"Every effort moves you\"\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "token_ids = generate_text_sample(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(start_context, tokenizer),\n",
    "    max_new_tokens=10,\n",
    "    context_size=GPT_CONFIG_124M[\"context_length\"]\n",
    ")\n",
    "\n",
    "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f6a8f53c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create example inputs and targets\n",
    "inputs = torch.tensor([[16833, 3626, 6100],  # [\"every effort moves\",\n",
    "                      [40, 1107, 588]])      # \"I really like\"]\n",
    "\n",
    "targets = torch.tensor([[3626, 6100, 345],      # [\" effort moves you\",\n",
    "                        [1107, 588, 11311]])    # \" really like chocolate\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "012c9dc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 50257])\n"
     ]
    }
   ],
   "source": [
    "# Feed examples into model to get probilities\n",
    "with torch.no_grad():\n",
    "    logits = model(inputs)\n",
    "probas = torch.softmax(logits, dim=-1)\n",
    "print(probas.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "af258b69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token IDs:\n",
      " tensor([[[16657],\n",
      "         [  339],\n",
      "         [42826]],\n",
      "\n",
      "        [[49906],\n",
      "         [29669],\n",
      "         [41751]]])\n"
     ]
    }
   ],
   "source": [
    "# greedily pick next token\n",
    "token_ids = torch.argmax(probas, dim=-1, keepdim=True) # keepdim retains number of dimensions. False squeezes dim \n",
    "print(\"Token IDs:\\n\", token_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f2c41f4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Targets batch 1:  effort moves you\n",
      "Outputs batch 1:  Armed heNetflix\n"
     ]
    }
   ],
   "source": [
    "# Convert token IDs back into text\n",
    "print(f\"Targets batch 1: {token_ids_to_text(targets[0], tokenizer)}\")\n",
    "print(f\"Outputs batch 1: {token_ids_to_text(token_ids[0].flatten(), tokenizer)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b0c50822",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text 1: tensor([7.4540e-05, 3.1061e-05, 1.1563e-05])\n",
      "Text 2: tensor([1.0337e-05, 5.6776e-05, 4.7559e-06])\n"
     ]
    }
   ],
   "source": [
    "# Print initial softmax probabilities\n",
    "text_idx = 0\n",
    "target_probas_1 = probas[text_idx, [0, 1, 2], targets[text_idx]]\n",
    "print(\"Text 1:\", target_probas_1)\n",
    "\n",
    "text_idx = 1\n",
    "target_probas_2 = probas[text_idx, [0, 1, 2], targets[text_idx]]\n",
    "print(\"Text 2:\", target_probas_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0b3212f",
   "metadata": {},
   "source": [
    "## Calculate Loss\n",
    "logits -> probabilities -> target probabilities -> log probabilities -> average log probability -> negative average log probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "937c0a77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ -9.5042, -10.3796, -11.3677, -11.4798,  -9.7764, -12.2561])\n"
     ]
    }
   ],
   "source": [
    "log_probas = torch.log(torch.cat((target_probas_1, target_probas_2)))\n",
    "print(log_probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9921bda8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-10.7940)\n"
     ]
    }
   ],
   "source": [
    "avg_log_probas = torch.mean(log_probas)\n",
    "print(avg_log_probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "17833af6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(10.7940)\n"
     ]
    }
   ],
   "source": [
    "neg_avg_log_probas = avg_log_probas * -1\n",
    "print(neg_avg_log_probas) # Easier to push negative log down to 1 with gradient decent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29a54160",
   "metadata": {},
   "source": [
    "Note: Cross Entropy Loss measures the difference between two probability distributions\n",
    "    cross entropy for discrete outcomes is synonymous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e302770e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logits shape: torch.Size([2, 3, 50257])\n",
      "Target shape: torch.Size([2, 3])\n"
     ]
    }
   ],
   "source": [
    "print(\"Logits shape:\", logits.shape)\n",
    "print(\"Target shape:\", targets.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "77847872",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flattened logits: torch.Size([6, 50257])\n",
      "Flattened targets: torch.Size([6])\n"
     ]
    }
   ],
   "source": [
    "# Flatten over batch for cross entropy\n",
    "logits_flat = logits.flatten(0, 1)\n",
    "targets_flat = targets.flatten()\n",
    "print(\"Flattened logits:\", logits_flat.shape)\n",
    "print(\"Flattened targets:\", targets_flat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2b568689",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(10.7940)\n"
     ]
    }
   ],
   "source": [
    "loss = torch.nn.functional.cross_entropy(logits_flat, targets_flat)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69a9e844",
   "metadata": {},
   "source": [
    "Note: Perplexity measures how well the probability distribution predicted by the model matches the actual distribution of the words in the dataset.\n",
    "\n",
    "The number represents how many of the tokens in the vocabulary it is unsure about."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ddf2d58b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(48725.8672)\n"
     ]
    }
   ],
   "source": [
    "perplexity = torch.exp(loss)\n",
    "print(perplexity)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6c54764",
   "metadata": {},
   "source": [
    "### Calculating the training and validation set losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9c4dad62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load The Verdict\n",
    "file_path = \"../the-verdict.txt\"\n",
    "with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "    text_data = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e69d4da7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Characters: 20479\n",
      "Tokens: 5145\n"
     ]
    }
   ],
   "source": [
    "# Get stats\n",
    "total_characters = len(text_data)\n",
    "total_tokens = len(tokenizer.encode(text_data))\n",
    "print(\"Characters:\", total_characters)\n",
    "print(\"Tokens:\", total_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "00d346be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create training split\n",
    "train_ratio = 0.90\n",
    "split_idx = int(train_ratio * len(text_data))\n",
    "train_data = text_data[:split_idx]\n",
    "val_data = text_data[split_idx:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "221fb567",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data loaders\n",
    "from chapter_2.chapter02 import create_dataloader_v1\n",
    "torch.manual_seed(123)\n",
    "\n",
    "train_loader = create_dataloader_v1(\n",
    "    txt=train_data,\n",
    "    batch_size=2,\n",
    "    max_length=GPT_CONFIG_124M[\"context_length\"],\n",
    "    stride=GPT_CONFIG_124M[\"context_length\"],\n",
    "    shuffle=False,\n",
    "    drop_last=False,\n",
    "    num_workers=0\n",
    ")\n",
    "val_loader = create_dataloader_v1(\n",
    "    txt=val_data,\n",
    "    batch_size=2,\n",
    "    max_length=GPT_CONFIG_124M[\"context_length\"],\n",
    "    stride=GPT_CONFIG_124M[\"context_length\"],\n",
    "    shuffle=False,\n",
    "    drop_last=False,\n",
    "    num_workers=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b0c40e9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loader:\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "\n",
      "Validation loader:\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n"
     ]
    }
   ],
   "source": [
    "# Double check loaders\n",
    "print(\"Train loader:\")\n",
    "for x, y in train_loader:\n",
    "    print(x.shape, y.shape)\n",
    "\n",
    "print(\"\\nValidation loader:\")\n",
    "for x, y in val_loader:\n",
    "    print(x.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bb0efe69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate the cross entropy loss of a given batch\n",
    "def calc_loss_batch(input_batch, target_batch, model, device):\n",
    "    input_batch = input_batch.to(device)\n",
    "    target_batch = target_batch.to(device)\n",
    "    logits = model(input_batch)\n",
    "    loss = torch.nn.functional.cross_entropy(\n",
    "        logits.flatten(0, 1), target_batch.flatten()\n",
    "    )\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b272ae5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to compute training and validation loss\n",
    "def calc_loss_loader(data_loader, model, device, num_batches=None):\n",
    "    total_loss = 0\n",
    "    if len(data_loader) == 0:\n",
    "        return float(\"nan\")\n",
    "    elif num_batches is None:\n",
    "        num_batches = len(data_loader)\n",
    "    else:\n",
    "        num_batches = min(num_batches, len(data_loader))\n",
    "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
    "        # Get loss over each batch\n",
    "        if i < num_batches:\n",
    "            loss = calc_loss_batch(\n",
    "                input_batch, target_batch, model, device\n",
    "            )\n",
    "            total_loss += loss.item()\n",
    "        else:\n",
    "            break\n",
    "    # Average loss per batch\n",
    "    return total_loss / num_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bfcecf8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 10.987583584255642\n",
      "Validation loss: 10.98110580444336\n"
     ]
    }
   ],
   "source": [
    "# Calculate loss over training and validation data loaders\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "with torch.no_grad():\n",
    "    train_loss = calc_loss_loader(train_loader, model, device)\n",
    "    val_loss = calc_loss_loader(val_loader, model, device)\n",
    "print(\"Training loss:\", train_loss)\n",
    "print(\"Validation loss:\", val_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56290375",
   "metadata": {},
   "source": [
    "## Training an LLM\n",
    "iterate over training epochs --> iterate over batches in each training epoch --> reset loss gradients from previous batch iteration --> calculate loss on current batch --> backward pass to calculate loss gradients --> update model weights using loss gradients --> print training and validation set losses --> generate sample text for visual inspection --> beginning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cbf167a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation function\n",
    "def evaluate_model(model, train_loader, val_loader, device, eval_iter):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        train_loss = calc_loss_loader(\n",
    "            train_loader, model, device, num_batches=eval_iter\n",
    "        )\n",
    "        val_loss = calc_loss_loader(\n",
    "            val_loader, model, device, num_batches=eval_iter\n",
    "        )\n",
    "    model.train()\n",
    "    return train_loss, val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c1fa6c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization\n",
    "def generate_and_print_sample(model, tokenizer, device, start_context):\n",
    "    model.eval()\n",
    "    context_size = model.pos_emb.weight.shape[0]\n",
    "    encoded = text_to_token_ids(start_context, tokenizer).to(device)\n",
    "    with torch.no_grad():\n",
    "        token_ids = generate_text_sample(\n",
    "            model=model,\n",
    "            idx=encoded,\n",
    "            max_new_tokens=50,\n",
    "            context_size=context_size\n",
    "        )\n",
    "    decoded_text = token_ids_to_text(token_ids, tokenizer)\n",
    "    print(decoded_text.replace(\"\\n\", \" \"))\n",
    "    model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "42461dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement training flow\n",
    "def train_model_simple(model, train_loader, val_loader,\n",
    "                        optimizer, device, num_epochs,\n",
    "                        eval_freq, eval_iter, start_context, tokenizer):\n",
    "    # Initialize tracking\n",
    "    train_losses, val_losses, track_tokens_seen = [], [], []\n",
    "    tokens_seen, global_step = 0, -1\n",
    "\n",
    "    # Main training loop\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        for input_batch, target_batch in train_loader:\n",
    "            optimizer.zero_grad() # reset loss gradients\n",
    "            loss = calc_loss_batch(\n",
    "                input_batch, target_batch, model, device\n",
    "            )\n",
    "            loss.backward() # calculate loss gradients\n",
    "            optimizer.step() # updates model weights using loss grads\n",
    "            tokens_seen += input_batch.numel()\n",
    "            global_step += 1\n",
    "\n",
    "            # Validate\n",
    "            if global_step % eval_freq == 0:\n",
    "                train_loss, val_loss = evaluate_model(\n",
    "                    model, train_loader, val_loader, device, eval_iter\n",
    "                )\n",
    "                train_losses.append(train_loss)\n",
    "                val_losses.append(val_loss)\n",
    "                track_tokens_seen.append(tokens_seen)\n",
    "                print(f\"Ep {epoch+1} (Step {global_step:06d}): \"\n",
    "                      f\"Train loss {train_loss:.3f}, \"\n",
    "                      f\"Val loss {val_loss:.3f}\"\n",
    "                )\n",
    "        \n",
    "        generate_and_print_sample(\n",
    "            model, tokenizer, device, start_context\n",
    "        )\n",
    "    return train_losses, val_losses, track_tokens_seen"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e91a569",
   "metadata": {},
   "source": [
    "Note: AdamW improves weight decay to minimize model complexity and prevent overfitting by penalizing larger weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "69e9adf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 1 (Step 000000): Train loss 9.749, Val loss 10.117\n",
      "Ep 1 (Step 000005): Train loss 8.008, Val loss 8.516\n",
      "Every effort moves you,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,\n",
      "Ep 2 (Step 000010): Train loss 6.738, Val loss 7.207\n",
      "Ep 2 (Step 000015): Train loss 6.028, Val loss 6.748\n",
      "Every effort moves you, the                                                \n",
      "Ep 3 (Step 000020): Train loss 5.475, Val loss 6.578\n",
      "Ep 3 (Step 000025): Train loss 5.490, Val loss 6.539\n",
      "Every effort moves you.                                                 \n",
      "Ep 4 (Step 000030): Train loss 5.097, Val loss 6.438\n",
      "Ep 4 (Step 000035): Train loss 4.717, Val loss 6.329\n",
      "Every effort moves you.                                                 \n",
      "Ep 5 (Step 000040): Train loss 4.208, Val loss 6.307\n",
      "Every effort moves you know he was not that my a--as he had been his painting.                                   \n",
      "Ep 6 (Step 000045): Train loss 3.687, Val loss 6.260\n",
      "Ep 6 (Step 000050): Train loss 3.195, Val loss 6.183\n",
      "Every effort moves you know he was not that I felt able to the end                                       \n",
      "Ep 7 (Step 000055): Train loss 2.749, Val loss 6.174\n",
      "Ep 7 (Step 000060): Train loss 2.449, Val loss 6.174\n",
      "Every effort moves you know he was not that my hostess was to the fact with a little a little to have to me--and me to have to see a little of the his glory, he had been his painting, I had been his pictures--and I had\n",
      "Ep 8 (Step 000065): Train loss 1.971, Val loss 6.251\n",
      "Ep 8 (Step 000070): Train loss 1.628, Val loss 6.170\n",
      "Every effort moves you know.\"    I glanced after him, and a me--had not to me--I must!                 \"I had a little the me.  \n",
      "Ep 9 (Step 000075): Train loss 1.274, Val loss 6.262\n",
      "Ep 9 (Step 000080): Train loss 1.083, Val loss 6.222\n",
      "Every effort moves you know,\" was one of the axioms he laid down the frame. \"I was no great surprise to me.     \"--as I was his pictures--and I had the donkey. \"strongest,\" she was\n",
      "Ep 10 (Step 000085): Train loss 0.761, Val loss 6.348\n",
      "Every effort moves you?\"  \"Yes--quite insensible to the fact with a laugh: \"Yes--and by me!\"  He laughed again, the moment--as Jack himself, one might put it, the donkey. \"There were days when I\n"
     ]
    }
   ],
   "source": [
    "# Run a small training\n",
    "torch.manual_seed(123)\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.to(device)\n",
    "optimizer = torch.optim.AdamW(\n",
    "    params=model.parameters(),\n",
    "    lr=0.0004,\n",
    "    weight_decay=0.1\n",
    ")\n",
    "num_epochs = 10\n",
    "train_losses, val_losses, tokens_seen = train_model_simple(\n",
    "    model, train_loader, val_loader, optimizer, device,\n",
    "    num_epochs=num_epochs, eval_freq=5, eval_iter=5,\n",
    "    start_context=\"Every effort moves you\", tokenizer=tokenizer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "51d69a59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot losses\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "\n",
    "def plot_losses(epochs_seen, tokens_seen, train_losses, val_losses):\n",
    "    fig, ax1 = plt.subplots(figsize=(5, 3))\n",
    "    ax1.plot(epochs_seen, train_losses, label=\"Training loss\")\n",
    "    ax1.plot(\n",
    "        epochs_seen, val_losses, linestyle=\"-.\", label=\"Validation loss\"\n",
    "    )\n",
    "    ax1.set_xlabel(\"Epochs\")\n",
    "    ax1.set_ylabel(\"Loss\")\n",
    "    ax1.legend(loc=\"upper right\")\n",
    "    ax1.xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "    ax2 = ax1.twiny()\n",
    "    ax2.set_xlabel(\"Tokens seen\")\n",
    "    fig.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
    "plot_losses(epochs_tensor, tokens_seen, train_losses, val_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5f28ae7",
   "metadata": {},
   "source": [
    "For a larger dataset, see the Project Gutenberg with 60,000 public domain books\n",
    "\n",
    "Note: It is common to train for 1 epoch with very large datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5ae3702",
   "metadata": {},
   "source": [
    "## Decoding (Generation) Strategies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6e2c3f80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (tok_emb): Embedding(50257, 768)\n",
       "  (pos_emb): Embedding(256, 768)\n",
       "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Move model to cpu if it was one GPU and turn off training\n",
    "model.to(\"cpu\")\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "65d4e8ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text:\n",
      " Every effort moves you?\"\n",
      "\n",
      "\"Yes--quite insensible to the fact with a laugh: \"Yes--and by me!\"\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Put model through text generation\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "token_ids = generate_text_sample(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(\"Every effort moves you\", tokenizer),\n",
    "    max_new_tokens=25,\n",
    "    context_size=GPT_CONFIG_124M[\"context_length\"]\n",
    ")\n",
    "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1619ad5d",
   "metadata": {},
   "source": [
    "### Temperature Scaling\n",
    "Adds a probabilistic selection process to the next-token generation task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "de8513bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example vocab\n",
    "vocab = {\n",
    "    \"closer\": 0,\n",
    "    \"every\": 1,\n",
    "    \"effort\": 2,\n",
    "    \"forward\": 3,\n",
    "    \"inches\": 4,\n",
    "    \"moves\": 5,\n",
    "    \"pizza\": 6,\n",
    "    \"toward\": 7,\n",
    "    \"you\": 8\n",
    "}\n",
    "inverse_vocab = {v: k for k, v in vocab.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e6ef9d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example logits\n",
    "next_token_logits = torch.tensor(\n",
    "    [4.51, 0.89, -1.90, 6.75, 1.63, -1.62, -1.89, 6.28, 1.79]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "819e6cbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "forward\n"
     ]
    }
   ],
   "source": [
    "# Greedily select\n",
    "probas = torch.softmax(next_token_logits, dim=0)\n",
    "next_token_id = torch.argmax(probas).item()\n",
    "print(inverse_vocab[next_token_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "01ac7f5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "forward\n"
     ]
    }
   ],
   "source": [
    "# Implement probabilistic sampling process\n",
    "torch.manual_seed(123)\n",
    "next_token_id = torch.multinomial(probas, num_samples=1).item()\n",
    "print(inverse_vocab[next_token_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2bc79845",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "73 x closer\n",
      "0 x every\n",
      "0 x effort\n",
      "582 x forward\n",
      "2 x inches\n",
      "0 x moves\n",
      "0 x pizza\n",
      "343 x toward\n"
     ]
    }
   ],
   "source": [
    "# Illustrate multinomial sampling\n",
    "def print_sampled_tokens(probas):\n",
    "    torch.manual_seed(123)\n",
    "    sample = [torch.multinomial(probas, num_samples=1).item()\n",
    "              for i in range(1_000)]\n",
    "    sampled_ids = torch.bincount(torch.tensor(sample)) # counts the frequency of each value\n",
    "    for i, freq in enumerate(sampled_ids):\n",
    "        print(f\"{freq} x {inverse_vocab[i]}\")\n",
    "\n",
    "print_sampled_tokens(probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e3dcf3ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Controlling the distribution with temperature scaling\n",
    "def softmax_with_temperature(logits, temperature):\n",
    "    scaled_logits = logits / temperature\n",
    "    return torch.softmax(scaled_logits, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7a0acec0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Illustrate distributions\n",
    "temperatures = [5, 1, 0.1]\n",
    "scaled_probas = [softmax_with_temperature(next_token_logits, T)\n",
    "                                          for T in temperatures]\n",
    "x = torch.arange(len(vocab))\n",
    "bar_width = 0.15\n",
    "fig, ax = plt.subplots(figsize=(5,3))\n",
    "for i, T in enumerate(temperatures):\n",
    "    rects = ax.bar(x + i * bar_width, scaled_probas[i],\n",
    "                   bar_width, label=f'Temperature = {T}')\n",
    "ax.set_ylabel('Probability')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(vocab.keys(), rotation=90)\n",
    "ax.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2186767",
   "metadata": {},
   "source": [
    "### Top-k Sampling\n",
    "Restricts the sampled tokens to the top-k most likely tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0ec7bb9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top logits: tensor([6.7500, 6.2800, 4.5100])\n",
      "Top positions: tensor([3, 7, 0])\n"
     ]
    }
   ],
   "source": [
    "# Get top_k probability tokens\n",
    "top_k = 3\n",
    "top_logits, top_pos = torch.topk(next_token_logits, top_k)\n",
    "print(\"Top logits:\", top_logits) # descending order\n",
    "print(\"Top positions:\", top_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2dca956a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([4.5100,   -inf,   -inf, 6.7500,   -inf,   -inf,   -inf, 6.2800,   -inf])\n"
     ]
    }
   ],
   "source": [
    "# Set all lower probability tokens to -inf\n",
    "new_logits = torch.where(\n",
    "    condition=next_token_logits < top_logits[-1], # logits less than  the minimum of the top 3\n",
    "    input=torch.tensor(float('-inf')), # assign -inf to lower logits\n",
    "    other=next_token_logits # retrain original logits for top tokens\n",
    ")\n",
    "print(new_logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0867c6ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0615, 0.0000, 0.0000, 0.5775, 0.0000, 0.0000, 0.0000, 0.3610, 0.0000])\n"
     ]
    }
   ],
   "source": [
    "# Get new token probability\n",
    "topk_probas = torch.softmax(new_logits, dim=0)\n",
    "print(topk_probas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "547b764e",
   "metadata": {},
   "source": [
    "## Better Text Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "85446c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(model, idx, max_new_tokens, context_size,\n",
    "             temperature=0.0, top_k=None, eos_id=None):\n",
    "    for _ in range(max_new_tokens):\n",
    "        idx_cond = idx[:, -context_size:]\n",
    "        with torch.no_grad():\n",
    "            logits = model(idx_cond)\n",
    "        logits = logits[:, -1, :]\n",
    "        if top_k is not None:\n",
    "            top_logits, _ = torch.topk(logits, top_k)\n",
    "            min_val = top_logits[:, -1]\n",
    "            logits = torch.where(\n",
    "                logits < min_val,\n",
    "                torch.tensor(float('-inf')).to(logits.device),\n",
    "                logits\n",
    "            )\n",
    "        if temperature > 0.0:\n",
    "            logits = logits / temperature\n",
    "            probs = torch.softmax(logits, dim=-1)\n",
    "            idx_next = torch.multinomial(probs, num_samples=1)\n",
    "        else:\n",
    "            idx_next = torch.argmax(logits, dim=-1, keepdim=True)\n",
    "        if idx_next == eos_id:\n",
    "            break\n",
    "        idx = torch.cat((idx, idx_next), dim=1)\n",
    "    return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c6d43f11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text:\n",
      " Every effort moves you not look an down surprise. It is to have been an object for enough\n"
     ]
    }
   ],
   "source": [
    "# Example text generation \n",
    "torch.manual_seed(123)\n",
    "token_ids = generate(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(\"Every effort moves you\", tokenizer),\n",
    "    max_new_tokens=15,\n",
    "    context_size=GPT_CONFIG_124M[\"context_length\"],\n",
    "    top_k=25,\n",
    "    temperature=1.4\n",
    ")\n",
    "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cccd46da",
   "metadata": {},
   "source": [
    "## Loading and Saving Model Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8c7ecde4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save state_dict to file\n",
    "torch.save(model.state_dict(), \"model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "aebde81a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (tok_emb): Embedding(50257, 768)\n",
       "  (pos_emb): Embedding(256, 768)\n",
       "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load state_dict\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.load_state_dict(torch.load(\"model.pth\", map_location=device))\n",
    "model.eval()\n",
    "# Should save optimizer state as well to continue training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d602ce69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving model and optimizer\n",
    "torch.save({\n",
    "    \"model_state_dict\": model.state_dict(),\n",
    "    \"optimizer_state_dict\": optimizer.state_dict()\n",
    "    },\n",
    "    \"model_and_optimizer.pth\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9f8a687c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (tok_emb): Embedding(50257, 768)\n",
       "  (pos_emb): Embedding(256, 768)\n",
       "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Restoring model and optimizer states\n",
    "checkpoint = torch.load(\"model_and_optimizer.pth\", map_location=device)\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=5e-4, weight_decay=0.1)\n",
    "optimizer.load_state_dict(checkpoint[\"optimizer_state_dict\"])\n",
    "model.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "554142bc",
   "metadata": {},
   "source": [
    "## Loading Pretrained OpenAI Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "671e6a55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Using cached tensorflow-2.20.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.5 kB)\n",
      "Collecting tqdm\n",
      "  Using cached tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Collecting absl-py>=1.0.0 (from tensorflow)\n",
      "  Using cached absl_py-2.3.1-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting astunparse>=1.6.0 (from tensorflow)\n",
      "  Using cached astunparse-1.6.3-py2.py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting flatbuffers>=24.3.25 (from tensorflow)\n",
      "  Using cached flatbuffers-25.9.23-py2.py3-none-any.whl.metadata (875 bytes)\n",
      "Collecting gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 (from tensorflow)\n",
      "  Using cached gast-0.6.0-py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting google_pasta>=0.1.1 (from tensorflow)\n",
      "  Using cached google_pasta-0.2.0-py3-none-any.whl.metadata (814 bytes)\n",
      "Collecting libclang>=13.0.0 (from tensorflow)\n",
      "  Using cached libclang-18.1.1-py2.py3-none-manylinux2010_x86_64.whl.metadata (5.2 kB)\n",
      "Collecting opt_einsum>=2.3.2 (from tensorflow)\n",
      "  Using cached opt_einsum-3.4.0-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: packaging in /home/eliholm3/.env/lib/python3.12/site-packages (from tensorflow) (25.0)\n",
      "Collecting protobuf>=5.28.0 (from tensorflow)\n",
      "  Using cached protobuf-6.33.0-cp39-abi3-manylinux2014_x86_64.whl.metadata (593 bytes)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /home/eliholm3/.env/lib/python3.12/site-packages (from tensorflow) (2.32.5)\n",
      "Requirement already satisfied: setuptools in /home/eliholm3/.env/lib/python3.12/site-packages (from tensorflow) (80.9.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /home/eliholm3/.env/lib/python3.12/site-packages (from tensorflow) (1.17.0)\n",
      "Collecting termcolor>=1.1.0 (from tensorflow)\n",
      "  Using cached termcolor-3.2.0-py3-none-any.whl.metadata (6.4 kB)\n",
      "Requirement already satisfied: typing_extensions>=3.6.6 in /home/eliholm3/.env/lib/python3.12/site-packages (from tensorflow) (4.15.0)\n",
      "Collecting wrapt>=1.11.0 (from tensorflow)\n",
      "  Using cached wrapt-2.0.1-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl.metadata (9.0 kB)\n",
      "Collecting grpcio<2.0,>=1.24.3 (from tensorflow)\n",
      "  Using cached grpcio-1.76.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (3.7 kB)\n",
      "Collecting tensorboard~=2.20.0 (from tensorflow)\n",
      "  Using cached tensorboard-2.20.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting keras>=3.10.0 (from tensorflow)\n",
      "  Using cached keras-3.12.0-py3-none-any.whl.metadata (5.9 kB)\n",
      "Requirement already satisfied: numpy>=1.26.0 in /home/eliholm3/.env/lib/python3.12/site-packages (from tensorflow) (2.3.4)\n",
      "Collecting h5py>=3.11.0 (from tensorflow)\n",
      "  Using cached h5py-3.15.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (3.0 kB)\n",
      "Collecting ml_dtypes<1.0.0,>=0.5.1 (from tensorflow)\n",
      "  Using cached ml_dtypes-0.5.3-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (8.9 kB)\n",
      "Collecting wheel<1.0,>=0.23.0 (from astunparse>=1.6.0->tensorflow)\n",
      "  Using cached wheel-0.45.1-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting rich (from keras>=3.10.0->tensorflow)\n",
      "  Using cached rich-14.2.0-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting namex (from keras>=3.10.0->tensorflow)\n",
      "  Using cached namex-0.1.0-py3-none-any.whl.metadata (322 bytes)\n",
      "Collecting optree (from keras>=3.10.0->tensorflow)\n",
      "  Using cached optree-0.17.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (33 kB)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/eliholm3/.env/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/eliholm3/.env/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/eliholm3/.env/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/eliholm3/.env/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (2025.10.5)\n",
      "Collecting markdown>=2.6.8 (from tensorboard~=2.20.0->tensorflow)\n",
      "  Using cached markdown-3.10-py3-none-any.whl.metadata (5.1 kB)\n",
      "Requirement already satisfied: pillow in /home/eliholm3/.env/lib/python3.12/site-packages (from tensorboard~=2.20.0->tensorflow) (12.0.0)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard~=2.20.0->tensorflow)\n",
      "  Using cached tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl.metadata (1.1 kB)\n",
      "Collecting werkzeug>=1.0.1 (from tensorboard~=2.20.0->tensorflow)\n",
      "  Using cached werkzeug-3.1.3-py3-none-any.whl.metadata (3.7 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /home/eliholm3/.env/lib/python3.12/site-packages (from werkzeug>=1.0.1->tensorboard~=2.20.0->tensorflow) (3.0.3)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich->keras>=3.10.0->tensorflow)\n",
      "  Using cached markdown_it_py-4.0.0-py3-none-any.whl.metadata (7.3 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/eliholm3/.env/lib/python3.12/site-packages (from rich->keras>=3.10.0->tensorflow) (2.19.2)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich->keras>=3.10.0->tensorflow)\n",
      "  Using cached mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Downloading tensorflow-2.20.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (620.7 MB)\n",
      "\u001b[2K   \u001b[91mâ”â”\u001b[0m\u001b[91mâ•¸\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m43.2/620.7 MB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:46\u001b[0m"
     ]
    }
   ],
   "source": [
    "#%pip install tensorflow tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9f96e05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download downloader from repo\n",
    "import urllib.request\n",
    "url = (\n",
    "    \"https://raw.githubusercontent.com/rasbt/\"\n",
    "    \"LLMs-from-scratch/main/ch05/\"\n",
    "    \"01_main-chapter-code/gpt_download.py\"\n",
    ")\n",
    "filename = url.split('/')[-1]\n",
    "urllib.request.urlretrieve(url, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9b917e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get architecture setting and params\n",
    "from gpt_download import download_and_load_gpt2\n",
    "settings, params = download_and_load_gpt2(\n",
    "    model_size=\"124M\", models_dir=\"../gpt2\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3388f556",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect setting and parameters\n",
    "print(\"Settings:\", settings)\n",
    "print(\"Parameter dictionary keys:\", params.keys()) # holds weight tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8e3502b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# View weights\n",
    "print(params[\"wte\"])\n",
    "print(\"Token embedding weight tensor dimensions:\", params[\"wte\"].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d24afd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model size configs\n",
    "# Each weights are open sourced\n",
    "model_configs = {\n",
    "    \"gpt2-small (124M)\": {\"emb_dim\": 768, \"n_layers\": 12, \"n_heads\": 12},\n",
    "    \"gpt2-medium (355M)\": {\"emb_dim\": 1024, \"n_layers\": 24, \"n_heads\": 16},\n",
    "    \"gpt2-large (774M)\": {\"emb_dim\": 1280, \"n_layers\": 36, \"n_heads\": 20},\n",
    "    \"gpt2-xl (1558M)\": {\"emb_dim\": 1600, \"n_layers\": 48, \"n_heads\": 25},\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f11d447f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure\n",
    "model_name = \"gpt2-small (124M)\"\n",
    "NEW_CONFIG = GPT_CONFIG_124M.copy()\n",
    "NEW_CONFIG.update(model_configs[model_name])\n",
    "NEW_CONFIG.update({\"context_length\": 1024}) # Change from 256 \n",
    "NEW_CONFIG.update({\"qkv_bias\": True}) # usually not used, but is for these weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2ddf73d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model instance\n",
    "gpt = GPTModel(NEW_CONFIG)\n",
    "gpt.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6d0d5c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Weight tensor loading function\n",
    "def assign(left, right):\n",
    "    if left.shape != right.shape:\n",
    "        raise ValueError(f\"Shape mismatch. Left: {left.shape}, \"\n",
    "                         f\"Right: {right.shape}\")\n",
    "    return torch.nn.Parameter(torch.tensor(right))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f00ab06a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Full weight loading function\n",
    "import numpy as np\n",
    "\n",
    "def load_weights_into_gpt(gpt, params):\n",
    "    gpt.pos_emb.weight = assign(gpt.pos_emb.weight, params['wpe'])\n",
    "    gpt.tok_emb.weight = assign(gpt.tok_emb.weight, params['wte'])\n",
    "    \n",
    "    for b in range(len(params[\"blocks\"])):\n",
    "        q_w, k_w, v_w = np.split(\n",
    "            (params[\"blocks\"][b][\"attn\"][\"c_attn\"])[\"w\"], 3, axis=-1)\n",
    "        gpt.trf_blocks[b].attn.W_query.weight = assign(\n",
    "            gpt.trf_blocks[b].attn.W_query.weight, q_w.T)\n",
    "        gpt.trf_blocks[b].attn.W_key.weight = assign(\n",
    "            gpt.trf_blocks[b].attn.W_key.weight, k_w.T)\n",
    "        gpt.trf_blocks[b].attn.W_value.weight = assign(\n",
    "            gpt.trf_blocks[b].attn.W_value.weight, v_w.T)\n",
    "\n",
    "        q_b, k_b, v_b = np.split(\n",
    "            (params[\"blocks\"][b][\"attn\"][\"c_attn\"])[\"b\"], 3, axis=-1)\n",
    "        gpt.trf_blocks[b].attn.W_query.bias = assign(\n",
    "            gpt.trf_blocks[b].attn.W_query.bias, q_b)\n",
    "        gpt.trf_blocks[b].attn.W_key.bias = assign(\n",
    "            gpt.trf_blocks[b].attn.W_key.bias, k_b)\n",
    "        gpt.trf_blocks[b].attn.W_value.bias = assign(\n",
    "            gpt.trf_blocks[b].attn.W_value.bias, v_b)\n",
    "\n",
    "        gpt.trf_blocks[b].attn.out_proj.weight = assign(\n",
    "            gpt.trf_blocks[b].attn.out_proj.weight, \n",
    "            params[\"blocks\"][b][\"attn\"][\"c_proj\"][\"w\"].T)\n",
    "        gpt.trf_blocks[b].attn.out_proj.bias = assign(\n",
    "            gpt.trf_blocks[b].attn.out_proj.bias, \n",
    "            params[\"blocks\"][b][\"attn\"][\"c_proj\"][\"b\"])\n",
    "\n",
    "        gpt.trf_blocks[b].ff.layers[0].weight = assign(\n",
    "            gpt.trf_blocks[b].ff.layers[0].weight, \n",
    "            params[\"blocks\"][b][\"mlp\"][\"c_fc\"][\"w\"].T)\n",
    "        gpt.trf_blocks[b].ff.layers[0].bias = assign(\n",
    "            gpt.trf_blocks[b].ff.layers[0].bias, \n",
    "            params[\"blocks\"][b][\"mlp\"][\"c_fc\"][\"b\"])\n",
    "        gpt.trf_blocks[b].ff.layers[2].weight = assign(\n",
    "            gpt.trf_blocks[b].ff.layers[2].weight, \n",
    "            params[\"blocks\"][b][\"mlp\"][\"c_proj\"][\"w\"].T)\n",
    "        gpt.trf_blocks[b].ff.layers[2].bias = assign(\n",
    "            gpt.trf_blocks[b].ff.layers[2].bias, \n",
    "            params[\"blocks\"][b][\"mlp\"][\"c_proj\"][\"b\"])\n",
    "\n",
    "        gpt.trf_blocks[b].norm1.scale = assign(\n",
    "            gpt.trf_blocks[b].norm1.scale, \n",
    "            params[\"blocks\"][b][\"ln_1\"][\"g\"])\n",
    "        gpt.trf_blocks[b].norm1.shift = assign(\n",
    "            gpt.trf_blocks[b].norm1.shift, \n",
    "            params[\"blocks\"][b][\"ln_1\"][\"b\"])\n",
    "        gpt.trf_blocks[b].norm2.scale = assign(\n",
    "            gpt.trf_blocks[b].norm2.scale, \n",
    "            params[\"blocks\"][b][\"ln_2\"][\"g\"])\n",
    "        gpt.trf_blocks[b].norm2.shift = assign(\n",
    "            gpt.trf_blocks[b].norm2.shift, \n",
    "            params[\"blocks\"][b][\"ln_2\"][\"b\"])\n",
    "\n",
    "    gpt.final_norm.scale = assign(gpt.final_norm.scale, params[\"g\"])\n",
    "    gpt.final_norm.shift = assign(gpt.final_norm.shift, params[\"b\"])\n",
    "    gpt.out_head.weight = assign(gpt.out_head.weight, params[\"wte\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4239ebe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use loaded weights\n",
    "load_weights_into_gpt(gpt, params)\n",
    "gpt.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb0af80e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating text with pretrained model\n",
    "torch.manual_seed(123)\n",
    "token_ids = generate(\n",
    "    model=gpt,\n",
    "    idx=text_to_token_ids(\"I beieve God exists because\", tokenizer).to(device),\n",
    "    max_new_tokens=200,\n",
    "    context_size=NEW_CONFIG[\"context_length\"],\n",
    "    top_k=50,\n",
    "    temperature=1.5\n",
    ")\n",
    "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1755220",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate gpt 2 on small dataset\n",
    "evaluate_model(gpt, train_loader, val_loader, device, 5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
